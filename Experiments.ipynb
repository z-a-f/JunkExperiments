{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.nn.quantized as nnq\n",
    "import torch.quantization as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_perf(y, qy, title='= Report =', show=True):\n",
    "    r\"\"\"\n",
    "    Unscaled Reports:\n",
    "        - MAE: Mean Absolute Error\n",
    "        - MaxAE: Maximum Absolute Error\n",
    "        - MSE: Mean Square Error\n",
    "        - MaxSE: Maximum Absolute Error\n",
    "    Scaled reports are the same as above scaled by either (y.max() - y.min()) or by (y.max() - y.min())^2.\n",
    "    Power reports:\n",
    "        - SNR: Signal-to-Noise ratio, computed as (y^2).mean() / MSE\n",
    "        - SNR(db): Signal-to-Noise raio, computed as 10 * log_10(SNR)\n",
    "    \"\"\"\n",
    "    if qy.is_quantized:\n",
    "        qy = qy.dequantize()\n",
    "    diff = y - qy\n",
    "    ret = {}\n",
    "    ret['MAE'] = diff.abs().mean().item()\n",
    "    ret['MaxAE'] = diff.abs().max().item()\n",
    "    ret['MSE'] = diff.square().mean().item()\n",
    "    ret['MaxSE'] = diff.square().max().item()\n",
    "    \n",
    "    y_range = y.max() - y.min().item()\n",
    "    y_range2 = y_range ** 2\n",
    "\n",
    "    for key in ['MAE', 'MaxAE']:\n",
    "        ret[key + '/|y|'] = ret[key] / y_range\n",
    "    for key in ['MSE', 'MaxSE']:\n",
    "        ret[key + '/|y|^2'] = ret[key] / y_range2\n",
    "        \n",
    "    mse = ret['MSE']\n",
    "    if mse == 0:\n",
    "        mse = 1e-15\n",
    "    ret['SNR'] = y.square().mean().item() / mse\n",
    "    ret['SNR(db)'] = 10 * np.log10(ret['SNR'])\n",
    "    \n",
    "    if show:\n",
    "        print(f'{title:^24}')\n",
    "        print('{:^24}'.format('Un-scaled'))\n",
    "        for key in ['MAE', 'MaxAE', 'MSE', 'MaxSE']:\n",
    "            value = ret[key]\n",
    "            print(f'{key:.<16}{value:.2e}')\n",
    "        print('{:^24}'.format('Scaled'))\n",
    "        for key in ['MAE/|y|', 'MaxAE/|y|', 'MSE/|y|^2', 'MaxSE/|y|^2']:\n",
    "            value = ret[key]\n",
    "            print(f'{key:.<16}{value:.2e}')\n",
    "        print('{:^24}'.format('Power'))\n",
    "        for key in ['SNR', 'SNR(db)']:\n",
    "            value = ret[key]\n",
    "            print(f'{key:.<16}{value:.2e}')\n",
    "    return ret\n",
    "\n",
    "def qparams_min_max(fmin, fmax, qtype):\n",
    "    qinfo = torch.iinfo(qtype)\n",
    "    qmin = qinfo.min\n",
    "    qmax = qinfo.max\n",
    "    \n",
    "    scale = (fmax - fmin + 1) / (qmax - qmin)\n",
    "    zero_point = int(round(qmin - fmin / scale))\n",
    "    \n",
    "    return scale, zero_point, qtype\n",
    "\n",
    "def qparams(x, qtype):\n",
    "    fmin = min(0, x.min().item())\n",
    "    fmax = max(0, x.max().item())\n",
    "    return qparams_min_max(fmin, fmax, qtype)\n",
    "\n",
    "def quantize(x, qtype):\n",
    "    s, z, qtype = qparams(x, qtype)\n",
    "    return torch.quantize_per_tensor(x, s, z, qtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "channels = 1\n",
    "length = 1024\n",
    "\n",
    "x = torch.randn((batch, channels, length))\n",
    "s, zp, qtype = qparams(x, torch.qint8)\n",
    "qx = quantize(x, torch.quint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinc(x):\n",
    "    return torch.where(x == 0,\n",
    "                       torch.tensor(1., device=x.device, dtype=x.dtype),\n",
    "                       torch.sin(x) / x)\n",
    "\n",
    "def symetric_hann(length: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    torchscript doesn't support `hann_window`, simple re-implementation.\n",
    "    \"\"\"\n",
    "    x = torch.linspace(-0.5, 0.5, length)\n",
    "    return torch.cos(math.pi * x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantizable layers rewrite\n",
    "import math\n",
    "\n",
    "class Upsample2Layer(nn.Module):  \n",
    "    def __init__(self, in_channels: int = 1, zeros: int = 56):\n",
    "        super(Upsample2Layer, self).__init__()\n",
    "        self.zeros = zeros\n",
    "        kernel = self.make_kernel()\n",
    "        self.conv = nn.Conv1d(in_channels, in_channels, zeros, bias=False, padding=zeros)\n",
    "        self.conv.weight = nn.Parameter(kernel)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_kernel(zeros: int = 56):\n",
    "        win = symetric_hann(4 * zeros + 1)\n",
    "        winodd = win[1::2]\n",
    "        t = torch.linspace(-zeros + 0.5, zeros - 0.5, 2 * zeros)\n",
    "        t *= math.pi\n",
    "        kernel = (sinc(t) * winodd).view(1, 1, -1)\n",
    "        return kernel\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        b, c, l = x.shape\n",
    "        y = x.view(-1, 1, l)\n",
    "        y = self.conv(y)\n",
    "        y = y[:, :, 1:]\n",
    "        y = y.view(b, c, l)\n",
    "        y = torch.stack([x, y], dim=-1)\n",
    "        return y.view(b, c, -1)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_float(cls, mod):\n",
    "        new_mod = cls()\n",
    "        new_mod.zeros = mod.zeros\n",
    "        new_mod.conv = nnq.Conv1d.from_float(mod.conv)\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = Upsample 2x errors = \n",
      "       Un-scaled        \n",
      "MAE.............1.59e-02\n",
      "MaxAE...........1.08e-01\n",
      "MSE.............4.43e-04\n",
      "MaxSE...........1.16e-02\n",
      "         Scaled         \n",
      "MAE/|y|.........1.86e-03\n",
      "MaxAE/|y|.......1.25e-02\n",
      "MSE/|y|^2.......6.02e-06\n",
      "MaxSE/|y|^2.....1.57e-04\n",
      "         Power          \n",
      "SNR.............2.26e+03\n",
      "SNR(db).........3.35e+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zafar/Git/pytorch-dev/pytorch/torch/quantization/observer.py:115: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
     ]
    }
   ],
   "source": [
    "upsample = Upsample2Layer(channels)\n",
    "y = upsample(x)\n",
    "\n",
    "upsample.qconfig = tq.default_qconfig\n",
    "q_upsample = tq.prepare(upsample, inplace=False)\n",
    "q_upsample(x)  # calibrate\n",
    "tq.convert(q_upsample, inplace=True)\n",
    "qy = q_upsample(qx)\n",
    "\n",
    "perf = check_perf(y, qy, show=True, title=\"= Upsample 2x errors =\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample2Layer(nn.Module):  \n",
    "    def __init__(self, in_channels: int = 1, zeros: int = 56):\n",
    "        super(Downsample2Layer, self).__init__()\n",
    "        self.zeros = zeros\n",
    "        \n",
    "        kernel = self.make_kernel()\n",
    "        self.conv = nn.Conv1d(in_channels, in_channels, zeros, bias=False, padding=zeros)\n",
    "        self.conv.weight = nn.Parameter(kernel)\n",
    "        \n",
    "        self.pad = nn.ConstantPad1d((0, 1), 0)\n",
    "        self.mul = nnq.FloatFunctional()\n",
    "        self.add = nnq.FloatFunctional()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_kernel(zeros: int = 56):\n",
    "        win = symetric_hann(4 * zeros + 1)\n",
    "        winodd = win[1::2]\n",
    "        t = torch.linspace(-zeros + 0.5, zeros - 0.5, 2 * zeros)\n",
    "        t *= math.pi\n",
    "        kernel = (sinc(t) * winodd).view(1, 1, -1)\n",
    "        return kernel\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if x.shape[-1] % 2:\n",
    "            x = self.pad(x)\n",
    "        xeven = x[:, :, ::2]\n",
    "        xodd = x[:, :, 1::2]\n",
    "        b, c, l = xodd.shape\n",
    "        xodd = xodd.reshape((-1, 1, l))\n",
    "        y = self.conv(xodd)\n",
    "        y = y[:, :, :-1]\n",
    "        y = y.view(b, c, l)\n",
    "        \n",
    "        y = self.add.add(y, xeven)\n",
    "        y = self.mul.mul_scalar(y, 0.5)\n",
    "        return y\n",
    "    \n",
    "    @classmethod\n",
    "    def from_float(cls, mod):\n",
    "        new_mod = cls()\n",
    "        new_mod.zeros = mod.zeros\n",
    "        new_mod.conv = nnq.Conv1d.from_float(mod.conv)\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= Downsample 2x errors =\n",
      "       Un-scaled        \n",
      "MAE.............1.51e-02\n",
      "MaxAE...........5.69e-02\n",
      "MSE.............3.49e-04\n",
      "MaxSE...........3.24e-03\n",
      "         Scaled         \n",
      "MAE/|y|.........2.76e-03\n",
      "MaxAE/|y|.......1.04e-02\n",
      "MSE/|y|^2.......1.16e-05\n",
      "MaxSE/|y|^2.....1.08e-04\n",
      "         Power          \n",
      "SNR.............1.44e+03\n",
      "SNR(db).........3.16e+01\n"
     ]
    }
   ],
   "source": [
    "downsample = Downsample2Layer(channels)\n",
    "y = downsample(x)\n",
    "\n",
    "# # qy = quantize(downsample(qx.dequantize()), qx.dtype).dequantize()\n",
    "\n",
    "downsample.qconfig = tq.default_qconfig\n",
    "q_downsample = tq.prepare(downsample, inplace=False)\n",
    "q_downsample(x)  # calibrate\n",
    "tq.convert(q_downsample, inplace=True)\n",
    "qy = q_downsample(qx)\n",
    "\n",
    "perf = check_perf(y, qy, show=True, title=\"= Downsample 2x errors =\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     = GLU errors =     \n",
      "       Un-scaled        \n",
      "MAE.............1.05e-02\n",
      "MaxAE...........3.77e-02\n",
      "MSE.............1.57e-04\n",
      "MaxSE...........1.42e-03\n",
      "         Scaled         \n",
      "MAE/|y|.........1.99e-03\n",
      "MaxAE/|y|.......7.18e-03\n",
      "MSE/|y|^2.......5.72e-06\n",
      "MaxSE/|y|^2.....5.16e-05\n",
      "         Power          \n",
      "SNR.............1.86e+03\n",
      "SNR(db).........3.27e+01\n"
     ]
    }
   ],
   "source": [
    "# Implemented in https://github.com/pytorch/pytorch/pull/42443\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super(GLU, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, qx):\n",
    "        if qx.is_quantized:\n",
    "            return self._qforward(qx)\n",
    "        else:\n",
    "            return self._forward(qx)\n",
    "    \n",
    "    def _forward(self, x):\n",
    "        return F.glu(x, self.dim)\n",
    "    \n",
    "    def _qforward(self, qx):\n",
    "        x = qx.dequantize()\n",
    "        y = F.glu(x, self.dim)\n",
    "        qy = torch.quantize_per_tensor(y, qx.q_scale(), qx.q_zero_point(), qx.dtype)\n",
    "        return qy\n",
    "\n",
    "glu = GLU(-1)\n",
    "y = glu(x)\n",
    "\n",
    "# Prep/Convert sohuld have no effect\n",
    "glu.qconfig = tq.default_qconfig\n",
    "q_glu = tq.prepare(glu, inplace=False)\n",
    "q_glu(x)\n",
    "tq.convert(q_glu, inplace=True)\n",
    "qy = q_glu(qx)\n",
    "\n",
    "perf = check_perf(y, qy, show=True, title=\"= GLU errors =\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented in https://github.com/pytorch/pytorch/pull/40371\n",
    "class ConvTranspose1d(nn.ConvTranspose1d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ConvTranspose1d, self).__init__(*args, **kwargs)\n",
    "        self.quant_stub = tq.QuantStub()\n",
    "        self.dequant_stub = tq.DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dequant_stub(x)\n",
    "        x = super(ConvTranspose1d, self).forward(x)\n",
    "        x = self.quant_stub(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= ConvTranspose1d errors =\n",
      "       Un-scaled        \n",
      "MAE.............5.90e-03\n",
      "MaxAE...........1.83e-02\n",
      "MSE.............4.87e-05\n",
      "MaxSE...........3.34e-04\n",
      "         Scaled         \n",
      "MAE/|y|.........2.10e-03\n",
      "MaxAE/|y|.......6.48e-03\n",
      "MSE/|y|^2.......6.13e-06\n",
      "MaxSE/|y|^2.....4.20e-05\n",
      "         Power          \n",
      "SNR.............2.14e+03\n",
      "SNR(db).........3.33e+01\n"
     ]
    }
   ],
   "source": [
    "conv_transpose = ConvTranspose1d(channels, channels, kernel_size=3, stride=2)\n",
    "y = conv_transpose(x)\n",
    "\n",
    "# Prep/Convert sohuld have no effect\n",
    "conv_transpose.qconfig = tq.default_qconfig\n",
    "q_conv_transpose = tq.prepare(conv_transpose, inplace=False)\n",
    "q_conv_transpose(x)\n",
    "tq.convert(q_conv_transpose, inplace=True)\n",
    "qy = q_conv_transpose(qx)\n",
    "\n",
    "perf = check_perf(y, qy, show=True, title=\"= ConvTranspose1d errors =\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuse the facebookreesearch/demucs + modify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "DEMUCS_PATH = os.path.join('~', 'Git', 'demucs')\n",
    "DEMUCS_PATH = os.path.expanduser(DEMUCS_PATH)\n",
    "if DEMUCS_PATH not in sys.path:\n",
    "    sys.path.append(DEMUCS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Demucs(\n",
       "  (encoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(1, 64, kernel_size=(8,), stride=(4,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (3): GLU(dim=1)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(64, 96, kernel_size=(8,), stride=(4,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "      (3): GLU(dim=1)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(96, 144, kernel_size=(8,), stride=(4,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(144, 288, kernel_size=(1,), stride=(1,))\n",
       "      (3): GLU(dim=1)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(144, 216, kernel_size=(8,), stride=(4,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(216, 432, kernel_size=(1,), stride=(1,))\n",
       "      (3): GLU(dim=1)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv1d(216, 324, kernel_size=(8,), stride=(4,))\n",
       "      (1): ReLU()\n",
       "      (2): Conv1d(324, 648, kernel_size=(1,), stride=(1,))\n",
       "      (3): GLU(dim=1)\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(324, 648, kernel_size=(3,), stride=(1,))\n",
       "      (1): GLU(dim=1)\n",
       "      (2): ConvTranspose1d(324, 216, kernel_size=(8,), stride=(4,))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(216, 432, kernel_size=(3,), stride=(1,))\n",
       "      (1): GLU(dim=1)\n",
       "      (2): ConvTranspose1d(216, 144, kernel_size=(8,), stride=(4,))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(144, 288, kernel_size=(3,), stride=(1,))\n",
       "      (1): GLU(dim=1)\n",
       "      (2): ConvTranspose1d(144, 96, kernel_size=(8,), stride=(4,))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(96, 192, kernel_size=(3,), stride=(1,))\n",
       "      (1): GLU(dim=1)\n",
       "      (2): ConvTranspose1d(96, 64, kernel_size=(8,), stride=(4,))\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "      (1): GLU(dim=1)\n",
       "      (2): ConvTranspose1d(64, 4, kernel_size=(8,), stride=(4,))\n",
       "    )\n",
       "  )\n",
       "  (lstm): BLSTM(\n",
       "    (lstm): LSTM(324, 324, num_layers=2, bidirectional=True)\n",
       "    (linear): Linear(in_features=648, out_features=324, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from demucs.model import Demucs\n",
    "\n",
    "model = Demucs(audio_channels=1, depth=5, growth=1.5)\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
