{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.quantization as tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.quantized as nnq\n",
    "\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, transposed=False):\n",
    "        super().__init__()\n",
    "        if transposed:\n",
    "            self.conv = nn.ConvTranspose2d(3, 5, 3, bias=False).to(torch.float)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(3, 5, 3, bias=False).to(torch.float)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class AnnotatedConvModel(nn.Module):\n",
    "    def __init__(self, qengine, transposed=False):\n",
    "        super().__init__()\n",
    "        self.qconfig = tq.get_default_qconfig(qengine)\n",
    "        self.quant = tq.QuantStub()\n",
    "        if transposed:\n",
    "            self.conv = nn.ConvTranspose2d(3, 5, 3, bias=False).to(torch.float)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(3, 5, 3, bias=False).to(torch.float)\n",
    "        self.dequant = tq.DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_2d = [[torch.rand(1, 3, 10, 10, dtype=torch.float)] for _ in range(2)]\n",
    "x = img_data_2d[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Name                             Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  \n",
      "-------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "model_inference                  35.72%           57.460us         100.00%          160.840us        160.840us        1                \n",
      "aten::conv_transpose2d           3.72%            5.990us          63.32%           101.850us        101.850us        1                \n",
      "aten::convolution                2.96%            4.760us          59.60%           95.860us         95.860us         1                \n",
      "aten::_convolution               7.50%            12.070us         56.64%           91.100us         91.100us         1                \n",
      "aten::_convolution_nogroup       2.69%            4.320us          48.68%           78.290us         78.290us         1                \n",
      "aten::slow_conv_transpose2d      29.07%           46.750us         45.99%           73.970us         73.970us         1                \n",
      "aten::empty_like                 3.48%            5.590us          5.73%            9.220us          3.073us          3                \n",
      "aten::zero_                      1.86%            2.990us          4.86%            7.810us          7.810us          1                \n",
      "aten::fill_                      3.45%            5.550us          3.45%            5.550us          2.775us          2                \n",
      "aten::select                     2.65%            4.270us          3.39%            5.450us          2.725us          2                \n",
      "aten::empty                      3.21%            5.160us          3.21%            5.160us          1.290us          4                \n",
      "aten::resize_                    2.21%            3.560us          2.21%            3.560us          1.187us          3                \n",
      "aten::contiguous                 0.74%            1.190us          0.74%            1.190us          0.397us          3                \n",
      "aten::as_strided                 0.73%            1.180us          0.73%            1.180us          0.590us          2                \n",
      "-------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Self CPU time total: 160.840us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import profiler\n",
    "\n",
    "qengine = torch.backends.quantized.engine = 'qnnpack'\n",
    "anno_model = AnnotatedConvModel(qengine, transposed=True).eval()\n",
    "with profiler.profile(record_shapes=True) as prof:\n",
    "    with profiler.record_function(\"model_inference\"):\n",
    "        y = anno_model(x)\n",
    "        \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatedConvModel(\n",
      "  (quant): QuantStub()\n",
      "  (conv): ConvTranspose2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "AnnotatedConvModel(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (conv): ConvTranspose2d(\n",
      "    3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "AnnotatedConvModel(\n",
      "  (quant): QuantStub(\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (conv): ConvTranspose2d(\n",
      "    3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
      "    (activation_post_process): HistogramObserver()\n",
      "  )\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "AnnotatedConvModel(\n",
      "  (quant): Quantize(scale=tensor([0.0039]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (conv): QuantizedConvTranpose2d(3, 5, kernel_size=(3, 3), stride=(1, 1), scale=0.004635039251297712, zero_point=118)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "---------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Name                               Self CPU total %  Self CPU total   CPU total %      CPU total        CPU time avg     Number of Calls  \n",
      "---------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "model_inference                    6.00%            1.037ms          100.00%          17.269ms         17.269ms         1                \n",
      "quantized::conv_transpose2d        48.94%           8.452ms          49.16%           8.489ms          8.489ms          1                \n",
      "aten::dequantize                   44.71%           7.721ms          44.73%           7.725ms          7.725ms          1                \n",
      "aten::contiguous                   0.03%            5.730us          0.18%            30.530us         6.106us          5                \n",
      "aten::empty_like                   0.03%            5.860us          0.08%            13.690us         13.690us         1                \n",
      "aten::copy_                        0.06%            10.050us         0.06%            11.110us         11.110us         1                \n",
      "aten::quantize_per_tensor          0.06%            10.600us         0.06%            11.030us         11.030us         1                \n",
      "aten::_empty_affine_quantized      0.04%            6.620us          0.04%            6.620us          3.310us          2                \n",
      "aten::item                         0.01%            2.560us          0.03%            5.260us          2.630us          2                \n",
      "aten::empty                        0.03%            5.160us          0.03%            5.160us          2.580us          2                \n",
      "aten::q_zero_point                 0.03%            4.470us          0.03%            4.470us          1.117us          4                \n",
      "aten::q_scale                      0.02%            2.760us          0.02%            2.760us          0.920us          3                \n",
      "aten::_local_scalar_dense          0.02%            2.700us          0.02%            2.700us          1.350us          2                \n",
      "aten::qscheme                      0.01%            1.870us          0.01%            1.870us          0.623us          3                \n",
      "aten::set_quantizer_               0.00%            0.660us          0.00%            0.660us          0.660us          1                \n",
      "---------------------------------  ---------------  ---------------  ---------------  ---------------  ---------------  ---------------  \n",
      "Self CPU time total: 17.269ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_fn(model, data):\n",
    "    for inp in data:\n",
    "        model(*inp)\n",
    "\n",
    "anno_model_eager = tq.quantize(anno_model, eval_fn, img_data_2d)\n",
    "\n",
    "with profiler.profile(record_shapes=True) as prof:\n",
    "    with profiler.record_function(\"model_inference\"):\n",
    "        qy = anno_model_eager(img_data_2d[0][0])\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = b = 3\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      "  (func_add): FloatFunctional(\n",
      "    (activation_post_process): Identity()\n",
      "  )\n",
      "  (conv1): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (act1): Sigmoid()\n",
      "  (conv2): Conv2d(2, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (fc): Linear(in_features=72, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch.nn.quantized as nnq\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        self.func_add = nnq.FloatFunctional()\n",
    "        self.conv1 = nn.Conv2d(3, 2, 5, bias=None).to(dtype=torch.float)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        self.conv2 = nn.Conv2d(2, 2, 1, bias=None).to(dtype=torch.float)\n",
    "        self.fc = nn.Linear(72, 10).to(dtype=torch.float)\n",
    "        self.fc.qconfig = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.func_add.add(x, x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dequant(x)\n",
    "        x = x.view(-1, 72).contiguous()\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "model = SimpleModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1            [-1, 3, 10, 10]               0\n",
      "          Identity-2            [-1, 3, 10, 10]               0\n",
      "            Conv2d-3              [-1, 2, 6, 6]             150\n",
      "           Sigmoid-4              [-1, 2, 6, 6]               0\n",
      "            Conv2d-5              [-1, 2, 6, 6]               4\n",
      "       DeQuantStub-6              [-1, 2, 6, 6]               0\n",
      "            Linear-7                   [-1, 10]             730\n",
      "================================================================\n",
      "Total params: 884\n",
      "Trainable params: 884\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "X = np.random.rand(2, 3, 10, 10).astype(\"float32\")\n",
    "X_tuple = (X,)\n",
    "\n",
    "summary(model, X.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/quantization/observer.py:874: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n",
      "/home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/nn/quantized/modules/utils.py:10: UserWarning: 0quantize_tensor_per_tensor_affine current rounding mode is not set to round-to-nearest-ties-to-even (FE_TONEAREST). This will cause accuracy issues in quantized models. (Triggered internally at  /home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/aten/src/ATen/native/quantized/affine_quantizer.cpp:25.)\n",
      "  float(wt_scale), int(wt_zp), torch.qint8)\n"
     ]
    }
   ],
   "source": [
    "torch.backends.quantized.engine = \"qnnpack\"\n",
    "pt_inputs = tuple(torch.from_numpy(x) for x in X_tuple)\n",
    "model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "q_model = torch.quantization.prepare(model, inplace=False)\n",
    "q_model = torch.quantization.convert(q_model, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "          Quantize-1            [-1, 3, 10, 10]               0\n",
      "          Identity-2            [-1, 3, 10, 10]               0\n",
      "            Conv2d-3              [-1, 2, 6, 6]               0\n",
      "           Sigmoid-4              [-1, 2, 6, 6]               0\n",
      "            Conv2d-5              [-1, 2, 6, 6]               0\n",
      "        DeQuantize-6              [-1, 2, 6, 6]               0\n",
      "            Linear-7                   [-1, 10]             730\n",
      "================================================================\n",
      "Total params: 730\n",
      "Trainable params: 730\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(q_model, X.shape[1:], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(q_model, pt_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "buf = io.BytesIO()\n",
    "torch.jit.save(traced_model, buf)\n",
    "buf.seek(0)\n",
    "q_model = torch.jit.load(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.eval()\n",
    "output = q_model(*pt_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py:243: UserWarning: `add_node_names' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `add_node_names` argument will be ignored.\n",
      "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n",
      "/home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py:243: UserWarning: `do_constant_folding' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `do_constant_folding` argument will be ignored.\n",
      "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n"
     ]
    }
   ],
   "source": [
    "import caffe2.python.onnx.backend as c2\n",
    "\n",
    "input_names=[\"x\"]\n",
    "relaxed_check=True\n",
    "    \n",
    "f = io.BytesIO()\n",
    "torch.onnx.export(q_model, pt_inputs, f, input_names=input_names, example_outputs=output,\n",
    "                  operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)\n",
    "f.seek(0)\n",
    "onnx_model = onnx.load(f)\n",
    "caffe_res = c2.run_model(onnx_model, dict(zip(input_names, X_tuple)))[0]\n",
    "# Due to change in requantization logic for certain ops such conv, linear\n",
    "# in pytorch's integration of qnnpack, numerics may have a mismatc with C2.\n",
    "# This mismatch should not be off my more than 1.\n",
    "# This flag helps us override default behavior under certain circumstances.\n",
    "if relaxed_check:\n",
    "    output_diff = np.absolute(np.squeeze(output.detach().numpy()) - caffe_res)\n",
    "    max_diff = np.amax(output_diff)\n",
    "\n",
    "    # This check had to be changed to account for changes in\n",
    "    # qnnpack's requant logic.\n",
    "    np.testing.assert_(max_diff <= 1, \"Maximum absolute difference must be less than 1\")\n",
    "else:\n",
    "    np.testing.assert_almost_equal(output.detach().numpy(), caffe_res, decimal=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_test(model, sample_inputs, input_names=None, decimal=3, relaxed_check=False):\n",
    "    torch.backends.quantized.engine = \"qnnpack\"\n",
    "    pt_inputs = tuple(torch.from_numpy(x) for x in sample_inputs)\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "    q_model = torch.quantization.prepare(model, inplace=False)\n",
    "    q_model = torch.quantization.convert(q_model, inplace=False)\n",
    "\n",
    "    traced_model = torch.jit.trace(q_model, pt_inputs)\n",
    "    print(traced_model.graph)\n",
    "    buf = io.BytesIO()\n",
    "    torch.jit.save(traced_model, buf)\n",
    "    buf.seek(0)\n",
    "    q_model = torch.jit.load(buf)\n",
    "\n",
    "    q_model.eval()\n",
    "    output = q_model(*pt_inputs)\n",
    "\n",
    "    f = io.BytesIO()\n",
    "    torch.onnx.export(q_model, pt_inputs, f, input_names=input_names, example_outputs=output,\n",
    "                      operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)\n",
    "    f.seek(0)\n",
    "    onnx_model = onnx.load(f)\n",
    "    caffe_res = c2.run_model(onnx_model, dict(zip(input_names, sample_inputs)))[0]\n",
    "    # Due to change in requantization logic for certain ops such conv, linear\n",
    "    # in pytorch's integration of qnnpack, numerics may have a mismatc with C2.\n",
    "    # This mismatch should not be off my more than 1.\n",
    "    # This flag helps us override default behavior under certain circumstances.\n",
    "    if relaxed_check:\n",
    "        output_diff = np.absolute(np.squeeze(output.detach().numpy()) - caffe_res)\n",
    "        max_diff = np.amax(output_diff)\n",
    "\n",
    "        # This check had to be changed to account for changes in\n",
    "        # qnnpack's requant logic.\n",
    "        np.testing.assert_(max_diff <= 1, \"Maximum absolute difference must be less than 1\")\n",
    "    else:\n",
    "        np.testing.assert_almost_equal(output.detach().numpy(), caffe_res, decimal=decimal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.___torch_mangle_14.SimpleModel,\n",
      "      %X : Float(2:300, 3:100, 10:10, 10:1)):\n",
      "  %116 : __torch__.torch.nn.modules.linear.___torch_mangle_13.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
      "  %113 : __torch__.torch.nn.quantized.modules.DeQuantize = prim::GetAttr[name=\"dequant\"](%self.1)\n",
      "  %112 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name=\"conv2\"](%self.1)\n",
      "  %110 : __torch__.torch.nn.modules.activation.___torch_mangle_11.Sigmoid = prim::GetAttr[name=\"act1\"](%self.1)\n",
      "  %109 : __torch__.torch.nn.quantized.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%self.1)\n",
      "  %106 : __torch__.torch.nn.quantized.modules.functional_modules.QFunctional = prim::GetAttr[name=\"func_add\"](%self.1)\n",
      "  %107 : __torch__.torch.nn.modules.linear.___torch_mangle_10.Identity = prim::GetAttr[name=\"activation_post_process\"](%106)\n",
      "  %105 : __torch__.torch.nn.quantized.modules.Quantize = prim::GetAttr[name=\"quant\"](%self.1)\n",
      "  %125 : Tensor = prim::CallMethod[name=\"forward\"](%105, %X)\n",
      "  %53 : float = prim::Constant[value=1.]() # /home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/nn/quantized/modules/functional_modules.py:146:0\n",
      "  %54 : int = prim::Constant[value=0]() # /home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/nn/quantized/modules/functional_modules.py:146:0\n",
      "  %input.1 : QUInt8(2:300, 3:100, 10:10, 10:1) = quantized::add(%125, %125, %53, %54) # /home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/nn/quantized/modules/functional_modules.py:146:0\n",
      "  %126 : None = prim::CallMethod[name=\"forward\"](%107)\n",
      "  %127 : Tensor = prim::CallMethod[name=\"forward\"](%109, %input.1)\n",
      "  %128 : Tensor = prim::CallMethod[name=\"forward\"](%110, %127)\n",
      "  %129 : Tensor = prim::CallMethod[name=\"forward\"](%112, %128)\n",
      "  %130 : Tensor = prim::CallMethod[name=\"forward\"](%113, %129)\n",
      "  %88 : int = prim::Constant[value=-1]() # <ipython-input-11-d07edf2c1c8c>:20:0\n",
      "  %89 : int = prim::Constant[value=72]() # <ipython-input-11-d07edf2c1c8c>:20:0\n",
      "  %90 : int[] = prim::ListConstruct(%88, %89)\n",
      "  %91 : Float(2:72, 72:1) = aten::view(%130, %90) # <ipython-input-11-d07edf2c1c8c>:20:0\n",
      "  %92 : int = prim::Constant[value=0]() # <ipython-input-11-d07edf2c1c8c>:20:0\n",
      "  %input : Float(2:72, 72:1) = aten::contiguous(%91, %92) # <ipython-input-11-d07edf2c1c8c>:20:0\n",
      "  %131 : Tensor = prim::CallMethod[name=\"forward\"](%116, %input)\n",
      "  return (%131)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"tensor_cpu\" not implemented for 'Bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d07edf2c1c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgeneric_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelaxed_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c435c422cd54>\u001b[0m in \u001b[0;36mgeneric_test\u001b[0;34m(model, sample_inputs, input_names, decimal, relaxed_check)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     torch.onnx.export(q_model, pt_inputs, f, input_names=input_names, example_outputs=output,\n\u001b[0;32m---> 20\u001b[0;31m                       operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    206\u001b[0m                         \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mcustom_opsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_opsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    528\u001b[0m                                                             \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                                                             \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_do_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                                                             fixed_batch_size=fixed_batch_size)\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, propagate, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_function_substitution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mmethod_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lower_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0min_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             graph = _propagate_and_assign_input_shapes(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"tensor_cpu\" not implemented for 'Bool'"
     ]
    }
   ],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        self.func_add = nnq.FloatFunctional()\n",
    "        self.conv1 = nn.Conv2d(3, 2, 5, bias=None).to(dtype=torch.float)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        self.conv2 = nn.Conv2d(2, 2, 1, bias=None).to(dtype=torch.float)\n",
    "        self.fc = nn.Linear(72, 10).to(dtype=torch.float)\n",
    "        self.fc.qconfig = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.func_add.add(x, x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dequant(x)\n",
    "        x = x.view(-1, 72).contiguous()\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "x = np.random.rand(2, 3, 10, 10).astype(\"float32\")\n",
    "generic_test(SimpleModel(), (x,), input_names=[\"x\"], relaxed_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.___torch_mangle_18.SimpleModel,\n",
      "      %X : Float(2:300, 3:100, 10:10, 10:1)):\n",
      "  %116 : __torch__.torch.nn.modules.linear.___torch_mangle_17.Linear = prim::GetAttr[name=\"fc\"](%self.1)\n",
      "  %113 : __torch__.torch.nn.quantized.modules.___torch_mangle_11.DeQuantize = prim::GetAttr[name=\"dequant\"](%self.1)\n",
      "  %112 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name=\"conv2\"](%self.1)\n",
      "  %110 : __torch__.torch.nn.modules.activation.___torch_mangle_15.Sigmoid = prim::GetAttr[name=\"act1\"](%self.1)\n",
      "  %109 : __torch__.torch.nn.quantized.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name=\"conv1\"](%self.1)\n",
      "  %106 : __torch__.torch.nn.quantized.modules.functional_modules.___torch_mangle_13.QFunctional = prim::GetAttr[name=\"func_add\"](%self.1)\n",
      "  %107 : __torch__.torch.nn.modules.linear.___torch_mangle_12.Identity = prim::GetAttr[name=\"activation_post_process\"](%106)\n",
      "  %105 : __torch__.torch.nn.quantized.modules.___torch_mangle_10.Quantize = prim::GetAttr[name=\"quant\"](%self.1)\n",
      "  %125 : Tensor = prim::CallMethod[name=\"forward\"](%105, %X)\n",
      "  %53 : float = prim::Constant[value=1.]() # /home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/nn/quantized/modules/functional_modules.py:146:0\n",
      "  %54 : int = prim::Constant[value=0]() # /home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/nn/quantized/modules/functional_modules.py:146:0\n",
      "  %input.1 : QUInt8(2:300, 3:100, 10:10, 10:1) = quantized::add(%125, %125, %53, %54) # /home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/nn/quantized/modules/functional_modules.py:146:0\n",
      "  %126 : None = prim::CallMethod[name=\"forward\"](%107)\n",
      "  %127 : Tensor = prim::CallMethod[name=\"forward\"](%109, %input.1)\n",
      "  %128 : Tensor = prim::CallMethod[name=\"forward\"](%110, %127)\n",
      "  %129 : Tensor = prim::CallMethod[name=\"forward\"](%112, %128)\n",
      "  %130 : Tensor = prim::CallMethod[name=\"forward\"](%113, %129)\n",
      "  %88 : int = prim::Constant[value=-1]() # <ipython-input-3-452b144f2975>:29:0\n",
      "  %89 : int = prim::Constant[value=72]() # <ipython-input-3-452b144f2975>:29:0\n",
      "  %90 : int[] = prim::ListConstruct(%88, %89)\n",
      "  %91 : Float(2:72, 72:1) = aten::view(%130, %90) # <ipython-input-3-452b144f2975>:29:0\n",
      "  %92 : int = prim::Constant[value=0]() # <ipython-input-3-452b144f2975>:29:0\n",
      "  %input : Float(2:72, 72:1) = aten::contiguous(%91, %92) # <ipython-input-3-452b144f2975>:29:0\n",
      "  %131 : Tensor = prim::CallMethod[name=\"forward\"](%116, %input)\n",
      "  return (%131)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/quantization/observer.py:874: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n",
      "/home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py:243: UserWarning: `add_node_names' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `add_node_names` argument will be ignored.\n",
      "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n",
      "/home/zafar/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py:243: UserWarning: `do_constant_folding' can be set to True only when 'operator_export_type' is `ONNX`. Since 'operator_export_type' is not set to 'ONNX', `do_constant_folding` argument will be ignored.\n",
      "  \"`{}` argument will be ignored.\".format(arg_name, arg_name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"tensor_cpu\" not implemented for 'Bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-452b144f2975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m torch.onnx.export(q_model, pt_inputs, f, input_names=input_names, example_outputs=output,\n\u001b[0;32m---> 59\u001b[0;31m                   operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    206\u001b[0m                         \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                         \u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                         custom_opsets, enable_onnx_checker, use_external_data_format)\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_initializers_as_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mcustom_opsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_opsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_onnx_checker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             use_external_data_format=use_external_data_format)\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    528\u001b[0m                                                             \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpropagate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                                                             \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_do_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                                                             fixed_batch_size=fixed_batch_size)\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;31m# TODO: Don't allocate a in-memory string for the protobuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Git/pytorch-dev/pytorch-convtranspose-new/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, propagate, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_function_substitution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0mmethod_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lower_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0min_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             graph = _propagate_and_assign_input_shapes(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"tensor_cpu\" not implemented for 'Bool'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.quantized as nnq\n",
    "import numpy as np\n",
    "import io\n",
    "import onnx\n",
    "import caffe2.python.onnx.backend as c2\n",
    "\n",
    "class SimpleModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        self.func_add = nnq.FloatFunctional()\n",
    "        self.conv1 = nn.Conv2d(3, 2, 5, bias=None).to(dtype=torch.float)\n",
    "        self.act1 = nn.Sigmoid()\n",
    "        self.conv2 = nn.Conv2d(2, 2, 1, bias=None).to(dtype=torch.float)\n",
    "        self.fc = nn.Linear(72, 10).to(dtype=torch.float)\n",
    "        self.fc.qconfig = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.func_add.add(x, x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.dequant(x)\n",
    "        x = x.view(-1, 72).contiguous()\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "x = np.random.rand(2, 3, 10, 10).astype(\"float32\")\n",
    "# self.generic_test(SimpleModel(), (x,), input_names=[\"x\"], relaxed_check=True)\n",
    "\n",
    "model = SimpleModel()\n",
    "sample_inputs = (x,)\n",
    "input_names = ['x']\n",
    "relaxed_check = True\n",
    "\n",
    "torch.backends.quantized.engine = \"qnnpack\"\n",
    "pt_inputs = tuple(torch.from_numpy(x) for x in sample_inputs)\n",
    "model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "q_model = torch.quantization.prepare(model, inplace=False)\n",
    "q_model = torch.quantization.convert(q_model, inplace=False)\n",
    "\n",
    "traced_model = torch.jit.trace(q_model, pt_inputs)\n",
    "print(traced_model.graph)\n",
    "buf = io.BytesIO()\n",
    "torch.jit.save(traced_model, buf)\n",
    "buf.seek(0)\n",
    "q_model = torch.jit.load(buf)\n",
    "\n",
    "q_model.eval()\n",
    "output = q_model(*pt_inputs)\n",
    "\n",
    "f = io.BytesIO()\n",
    "torch.onnx.export(q_model, pt_inputs, f, input_names=input_names, example_outputs=output,\n",
    "                  operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)\n",
    "f.seek(0)\n",
    "onnx_model = onnx.load(f)\n",
    "caffe_res = c2.run_model(onnx_model, dict(zip(input_names, sample_inputs)))[0]\n",
    "# Due to change in requantization logic for certain ops such conv, linear\n",
    "# in pytorch's integration of qnnpack, numerics may have a mismatc with C2.\n",
    "# This mismatch should not be off my more than 1.\n",
    "# This flag helps us override default behavior under certain circumstances.\n",
    "if relaxed_check:\n",
    "    output_diff = np.absolute(np.squeeze(output.detach().numpy()) - caffe_res)\n",
    "    max_diff = np.amax(output_diff)\n",
    "\n",
    "    # This check had to be changed to account for changes in\n",
    "    # qnnpack's requant logic.\n",
    "    np.testing.assert_(max_diff <= 1, \"Maximum absolute difference must be less than 1\")\n",
    "else:\n",
    "    np.testing.assert_almost_equal(output.detach().numpy(), caffe_res, decimal=decimal)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
